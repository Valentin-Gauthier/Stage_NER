{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91406d9c",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5899f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "NER = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c543d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../ressources/20231101_raw.xlsx')\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58bc37",
   "metadata": {},
   "source": [
    "# Spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "115f41c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May  2 17:00:51 2025\n",
      "Fri May  2 17:02:05 2025\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "ner_spacy  = []\n",
    "ner_spacy_id = []\n",
    "for idx, bc in df.iterrows():    \n",
    "    desc = str(bc['desc'])\n",
    "    text = NER(desc)\n",
    "    tmp_1 = []\n",
    "    tmp_2 = []\n",
    "    for word in text.ents:\n",
    "        if (word.text,word.label_) not in tmp_1:\n",
    "            tmp_1.append((word.text,word.label_))\n",
    "            tmp_2.append((word.start, word.end))\n",
    "    ner_spacy.append(tmp_1)\n",
    "    ner_spacy_id.append(tmp_2)\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9fee166",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a = df['titles'].to_list()\n",
    "list_de = df['desc'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85b0ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_b = []\n",
    "list_c = []\n",
    "list_d = []\n",
    "list_e = []\n",
    "\n",
    "for i in range(len(list_a)):\n",
    "    de = list_de[i]\n",
    "    doc = NER(de)\n",
    "    ner = ner_spacy[i]\n",
    "    idx = ner_spacy_id[i]\n",
    "    t = list_a[i]\n",
    "    for n,l in zip(ner,idx):\n",
    "        list_b.append(t)\n",
    "        list_c.append(n[0])\n",
    "        list_d.append(n[1])\n",
    "        if l[0] < 10:\n",
    "            if l[1] + 8 > len(doc):\n",
    "                list_e.append(doc)\n",
    "            else:\n",
    "                list_e.append(doc[:l[1]+8])\n",
    "        else:\n",
    "            if l[1] + 8 > len(doc):\n",
    "                list_e.append(doc[l[0]-10:])\n",
    "            else:\n",
    "                list_e.append(doc[l[0]-10:l[1]+8])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b34fd803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner_spacy_loc = pd.DataFrame(zip(list_b,list_c,list_d,list_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "054aa18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>NER</th>\n",
       "      <th>NER_label</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Faster than fear</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>PER</td>\n",
       "      <td>(Ralf, a, pu, prouver, son, innocence, et, Sun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Faster than fear</td>\n",
       "      <td>Haffner</td>\n",
       "      <td>PER</td>\n",
       "      <td>(Elle, n', a, plus, rien, à, voir, avec, l', a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Faster than fear</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>LOC</td>\n",
       "      <td>(Haffner, ,, mais, celui-ci, demande, à, ne, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Faster than fear</td>\n",
       "      <td>Nora</td>\n",
       "      <td>LOC</td>\n",
       "      <td>(à, Sunny, ., D', ailleurs, ,, elle, est, pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Faster than fear</td>\n",
       "      <td>Marcel</td>\n",
       "      <td>PER</td>\n",
       "      <td>(vue, ,, Haffner, n', avoue, toujours, pas, où...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19189</th>\n",
       "      <td>Geld gezocht</td>\n",
       "      <td>Shana</td>\n",
       "      <td>PER</td>\n",
       "      <td>(de, leurs, deux, fils, ,, Elias, et, Noah, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19190</th>\n",
       "      <td>Geld gezocht</td>\n",
       "      <td>Jelle</td>\n",
       "      <td>PER</td>\n",
       "      <td>(deux, fils, ,, Elias, et, Noah, ,, que, Shana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19191</th>\n",
       "      <td>Geld gezocht</td>\n",
       "      <td>Lede</td>\n",
       "      <td>LOC</td>\n",
       "      <td>(Elias, et, Noah, ,, que, Shana, et, Jelle, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19192</th>\n",
       "      <td>Geld gezocht</td>\n",
       "      <td>Kristel</td>\n",
       "      <td>LOC</td>\n",
       "      <td>(un, petit, extra, ., Ils, demandent, alors, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19193</th>\n",
       "      <td>Geld gezocht</td>\n",
       "      <td>Kamel</td>\n",
       "      <td>LOC</td>\n",
       "      <td>(extra, ., Ils, demandent, alors, l', aide, de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19194 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 titles      NER NER_label  \\\n",
       "0      Faster than fear    Sunny       PER   \n",
       "1      Faster than fear  Haffner       PER   \n",
       "2      Faster than fear    Sunny       LOC   \n",
       "3      Faster than fear     Nora       LOC   \n",
       "4      Faster than fear   Marcel       PER   \n",
       "...                 ...      ...       ...   \n",
       "19189      Geld gezocht    Shana       PER   \n",
       "19190      Geld gezocht    Jelle       PER   \n",
       "19191      Geld gezocht     Lede       LOC   \n",
       "19192      Geld gezocht  Kristel       LOC   \n",
       "19193      Geld gezocht    Kamel       LOC   \n",
       "\n",
       "                                                    desc  \n",
       "0      (Ralf, a, pu, prouver, son, innocence, et, Sun...  \n",
       "1      (Elle, n', a, plus, rien, à, voir, avec, l', a...  \n",
       "2      (Haffner, ,, mais, celui-ci, demande, à, ne, p...  \n",
       "3      (à, Sunny, ., D', ailleurs, ,, elle, est, pers...  \n",
       "4      (vue, ,, Haffner, n', avoue, toujours, pas, où...  \n",
       "...                                                  ...  \n",
       "19189  (de, leurs, deux, fils, ,, Elias, et, Noah, ,,...  \n",
       "19190  (deux, fils, ,, Elias, et, Noah, ,, que, Shana...  \n",
       "19191  (Elias, et, Noah, ,, que, Shana, et, Jelle, vi...  \n",
       "19192  (un, petit, extra, ., Ils, demandent, alors, l...  \n",
       "19193  (extra, ., Ils, demandent, alors, l', aide, de...  \n",
       "\n",
       "[19194 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner_spacy_loc = df_ner_spacy_loc.rename(columns={0: \"titles\", 1: \"NER\",2:'NER_label',3:'desc'})\n",
    "df_ner_spacy_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8290cc41",
   "metadata": {},
   "source": [
    "# CasEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88e71bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from time import sleep\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4402f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for value in df['desc'].to_list():\n",
    "    text_file = open(r'C:\\\\Users\\\\valen\\Documents\\\\Informatique-L3\\\\Stage\\\\Stage\\\\Result\\\\Corpus\\\\np'+ str(count) +'.txt', \"w\",encoding=\"utf-8\")\n",
    "    my_string = value\n",
    "    text_file.write(my_string)\n",
    "    text_file.close()\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de313d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xml_files(path):\n",
    "    filenames = []\n",
    "    tmp_ar = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            tmp_ar.append(int(filename[2:-11]))\n",
    "    for i in np.sort(tmp_ar):\n",
    "        filenames.append(os.path.join(path, 'np' + str(i) + '.result.txt'))\n",
    "    return filenames\n",
    "\n",
    "def parsing(file_name):\n",
    "    file = open(file_name, \"r\",encoding=\"utf-8\")\n",
    "    contents = file.read() # done\n",
    "    soup = BeautifulSoup(contents, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "270986f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May  2 17:07:33 2025\n",
      "####\n",
      "Folder to process :  C:\\Users\\valen\\Documents\\Informatique-L3\\Stage\\Corpus \n",
      "Script :  CasEN_Analyse_synthese_grf.uniscript\n",
      "result.txt\n",
      "C:\\Users\\valen\\Documents\\Informatique-L3\\Stage\\Corpus\t\t -> results in : C:\\Users\\valen\\Documents\\Informatique-L3\\Stage\\Result\\Res_CasEN_Analyse_synthese_grf\n",
      "1 files to process with CasEN in  C:\\Users\\valen\\Documents\\Informatique-L3\\Stage\\Corpus\n",
      "C:\\Users\\valen\\AppData\\Local\\Unitex-GramLab\\App\\UnitexToolLogger.exe { BatchRunScript -e -i \"C:\\Users\\valen\\Documents\\Informatique-L3\\Stage\\Corpus\" -o \"C:\\Users\\valen\\Documents\\Informatique-L3\\Stage\\Result\\Res_CasEN_Analyse_synthese_grf\" -t1 \"C:\\Users\\valen\\Documents\\Informatique-L3\\Stage\\CasEN_fr.2.0\\my_CasEN_lingpkg.zip\" -f -s \"script\\CasEN_Analyse_synthese_grf.uniscript\" }\n",
      "Results stored in  C:\\Users\\valen\\Documents\\Informatique-L3\\Stage\\Result\\Res_CasEN_Analyse_synthese_grf\n",
      "C:\\Users\\valen\\Documents\\Informatique-L3\\Stage\\Corpus\n",
      "Fri May  2 17:09:48 2025\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "casen_notebook_path = \"C:\\\\Users\\\\valen\\\\Documents\\\\Informatique-L3\\\\Stage\\\\CasEN_fr.2.0\\\\CasEN.ipynb\"\n",
    "get_ipython().run_line_magic('run', str(casen_notebook_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bf22a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\valen\\\\Documents\\\\Informatique-L3\\\\Stage\\\\Stage\\\\Result\\\\CasEN_Result\\\\Res_CasEN_Analyse_synthese_grf\\\\\"\n",
    "filenames = get_xml_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c987077f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May  2 17:12:03 2025\n",
      "Fri May  2 17:12:03 2025\n"
     ]
    }
   ],
   "source": [
    "print(time.ctime())\n",
    "ner_casEN = []\n",
    "for filename in filenames:\n",
    "    soup = parsing(filename)\n",
    "    tmp_ner = []\n",
    "    for name in soup.findAll('persname'):\n",
    "        tmp_ner.append((name.text,'PER'))\n",
    "    for loc in soup.findAll(['placename','geoname']):\n",
    "        tmp_ner.append((loc.text,'LOC'))\n",
    "    for org in soup.findAll('orgname'):\n",
    "        tmp_ner.append((org.text,'ORG'))\n",
    "    ner_casEN.append(set(tmp_ner))\n",
    "print(time.ctime())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6153c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = []\n",
    "inter_len = []\n",
    "ner_len = []\n",
    "ner_casEN_len = []\n",
    "for a,b in zip(ner_spacy,ner_casEN):\n",
    "    a = set(a)\n",
    "    intersection.append(a.intersection(b))\n",
    "    inter_len.append(len(a.intersection(b)))\n",
    "    ner_len.append(len(a))\n",
    "    ner_casEN_len.append(len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60367d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['titles'].to_list()\n",
    "desc = df['desc'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ff93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_m = []\n",
    "list_n = []\n",
    "list_k = []\n",
    "list_l = []\n",
    "intersection_list = []\n",
    "for i in range(len(intersection)):\n",
    "    title = titles[i]\n",
    "    des = desc[i]\n",
    "    inter = list(intersection[i])\n",
    "    if len(inter) != 0:\n",
    "        for ners in inter:\n",
    "            list_m.append(title)\n",
    "            list_n.append(des)\n",
    "            list_k.append(ners[0])\n",
    "            list_l.append(ners[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a2d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner = pd.DataFrame(zip(list_m,list_k,list_l))\n",
    "df_ner = df_ner.rename(columns={0: \"titles\", 1: \"NER\",2:'NER_label'})\n",
    "df_ner = df_ner[df_ner['NER'] != 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce7da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner = df_ner.merge(df_ner_spacy_loc, on = ['titles','NER','NER_label']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_str(arr):\n",
    "    tmp =''\n",
    "    for i in arr:\n",
    "        tmp = tmp + ' ' + i.text\n",
    "    return tmp.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e185b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner['desc_str'] = df_ner['desc'].apply(token_str)\n",
    "df_ner = df_ner.drop_duplicates(subset = ['titles','NER','NER_label','desc_str'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5049798",
   "metadata": {},
   "source": [
    "# Intergrating\n",
    "- ner_spacy\n",
    "- ner_spacy_id\n",
    "- ner_casEN\n",
    "- intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507e39c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe5158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a = df['titles'].to_list()\n",
    "list_de = df['desc'].to_list()\n",
    "fix_len = len(list_a)\n",
    "list_idx = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8da4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_m = [] # title\n",
    "list_n = [] # NER\n",
    "list_l = [] # NER label\n",
    "list_k = [] # desc\n",
    "list_notation = []\n",
    "list_hash = []\n",
    "check_pos = []\n",
    "for i in range(fix_len):\n",
    "    index = list_idx[i]\n",
    "    print(index)\n",
    "    de = list_de[i]\n",
    "    doc = NER(de)\n",
    "    spacy = ner_spacy[i]\n",
    "    casEN = ner_casEN[i]\n",
    "    inter = list(intersection[i])\n",
    "    loc = ner_spacy_id[i]\n",
    "    t = list_a[i]\n",
    "    for n,l in zip(spacy,loc):\n",
    "        if n in inter:\n",
    "            list_notation.append('intersection')\n",
    "            list_m.append(t)\n",
    "            list_n.append(n[0])\n",
    "            list_l.append(n[1])\n",
    "            list_hash.append(index)\n",
    "        else:\n",
    "            list_notation.append('spacy')\n",
    "            list_m.append(t)\n",
    "            list_n.append(n[0])\n",
    "            list_l.append(n[1])\n",
    "            list_hash.append(index)\n",
    "        if l[0] < 8:\n",
    "            if l[1] + 8 > len(doc):\n",
    "                list_k.append(doc)\n",
    "            else:\n",
    "                list_k.append(doc[:l[1]+8])\n",
    "        else:\n",
    "            if l[1] + 8 > len(doc):\n",
    "                list_k.append(doc[l[0]-8:])\n",
    "            else:\n",
    "                list_k.append(doc[l[0]-8:l[1]+8])\n",
    "    for n in casEN:\n",
    "        if n not in inter:\n",
    "            list_notation.append('casEN')\n",
    "            list_m.append(t)\n",
    "            list_n.append(n[0])\n",
    "            list_l.append(n[1])\n",
    "            list_hash.append(index)\n",
    "            keyword = n[0].split(' ')[0]\n",
    "            words = de.split(' ')\n",
    "            if keyword in words:\n",
    "                pos = words.index(keyword)\n",
    "            else:\n",
    "                pos = -1\n",
    "                list_k.append(de)\n",
    "            if pos <= 5 and pos != -1:\n",
    "                if pos + 5 > len(words):\n",
    "                    list_k.append(' '.join(words))\n",
    "                else:\n",
    "                    list_k.append(' '.join(words[:pos+5]))\n",
    "            elif pos > 5 and pos != -1:\n",
    "                if pos + 5 > len(words):\n",
    "                    list_k.append(' '.join(words[pos-5:]))\n",
    "                else:\n",
    "                    list_k.append(' '.join(words[pos-5:pos+5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner_weekend = pd.DataFrame(zip(list_m,list_n,list_l,list_k,list_notation,list_hash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ner_weekend = df_ner_weekend.rename(columns={0: \"titles\", 1: \"NER\",2:'NER_label',3:'desc',4:'method',5:'hash'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
